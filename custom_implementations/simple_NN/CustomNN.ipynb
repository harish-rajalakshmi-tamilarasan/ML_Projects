{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3208abf-3e9c-427d-95ab-b05b0e9c1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942097ca-2e84-41ec-a0e5-50e1aa9f90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def sigmoid_derivative(X):\n",
    "    return X* (1-X)\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(0, X)\n",
    "\n",
    "def relu_derivative(X):\n",
    "    return np.where(X > 0, 1, 0)\n",
    "\n",
    "\n",
    "def crossentropyloss(y, y_preds):\n",
    "        y_preds = np.clip(y_preds, 1e-15, 1 - 1e-15)\n",
    "        loss = -np.mean( y * np.log(y_preds) + (1-y) * np.log(1-y_preds))\n",
    "        return loss\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, input_size: int, hidden_units: int, output_size:int):\n",
    "        # self.weights_ip = np.round(np.random.rand(input_size, hidden_units),2)  \n",
    "        # self.bias_ip = np.zeros((hidden_units)) \n",
    "        # self.weights_op = np.round(np.random.rand(hidden_units, output_size),2)  \n",
    "        # self.bias_op = np.zeros((output_size)) \n",
    "        self.weights_ip = np.random.randn(input_size, hidden_units) * np.sqrt(2 / (input_size + hidden_units))\n",
    "        self.bias_ip = np.zeros((1, hidden_units))  # Hidden bias (1, hidden_units)\n",
    "        self.weights_op = np.random.randn(hidden_units, output_size) * np.sqrt(2 / (hidden_units + output_size))\n",
    "        self.bias_op = np.zeros((1, output_size))\n",
    "        \n",
    "\n",
    "    def __call__(self,X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.m = X.shape[0]\n",
    "        self.X = X\n",
    "        self.a1 = (self.X @ self.weights_ip) + self.bias_ip\n",
    "        self.z1 = relu(self.a1)\n",
    "        self.a2 = (self.z1 @ self.weights_op) + self.bias_op\n",
    "        self.z2 = sigmoid(self.a2)\n",
    "        # print(\"weights= \",self.weights_ip,self.weights_op)\n",
    "        # print(\"bias= \",self.bias_ip,self.bias_op)\n",
    "        # print(\"a1= \",self.a1)\n",
    "        # print(\"z1= \",self.z1)\n",
    "        # print(\"a2= \",self.a2)\n",
    "        # print(\"z2= \",self.z2)\n",
    "        return self.z2\n",
    "\n",
    "    def loss(self,y):\n",
    "        return crossentropyloss(y,self.z2)\n",
    "\n",
    "    def backward(self, y, learning_rate):\n",
    "        dz2 = self.z2 - y        \n",
    "        dw2 = (1/self.m)*(self.z1.T @ dz2)\n",
    "        db2 = (1/self.m) * np.sum(dz2, axis=0, keepdims=True)\n",
    "        \n",
    "        da1 = dz2 @ self.weights_op.T\n",
    "        \n",
    "        dz1 = da1* relu_derivative(self.z1)\n",
    "        \n",
    "        dw1 = (1/self.m)*(self.X.T @ dz1)\n",
    "        db1 = (1/self.m) * np.sum(dz1, axis=0, keepdims=True) \n",
    "        \n",
    "        # print(\"dz2= \",dz2)\n",
    "        # print(\"dw2=\",dw2)\n",
    "        # print(\"db2=\",db2)\n",
    "        # print(\"da1= \",da1)\n",
    "        # print(\"dz1= \",dz1)\n",
    "        # print(\"dw1=\",dw1)\n",
    "        # print(\"db1=\",db1)\n",
    "        self.weights_op = self.weights_op - learning_rate*dw2\n",
    "        self.bias_op = self.bias_op - learning_rate*db2\n",
    "        self.weights_ip = self.weights_ip - learning_rate*dw1\n",
    "        self.bias_ip = self.bias_ip - learning_rate*db1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56d78871-3cce-482e-b1f1-0b40a4b783c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_samples = 200\n",
    "heights = np.random.normal(loc=170, scale=10, size=num_samples)  # Mean height ~ 170 cm\n",
    "weights = np.random.normal(loc=70, scale=15, size=num_samples)    # Mean weight ~ 70 kg\n",
    "\n",
    "bmi = weights / (heights / 100) ** 2  \n",
    "y = (bmi < 24.9).astype(int)  \n",
    "\n",
    "X = np.column_stack((heights, weights))\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "model = NeuralNetwork(X.shape[1],16,1)\n",
    "def train():\n",
    "    epochs = 100\n",
    "    for i in range(epochs):\n",
    "        y_preds = model(X)\n",
    "        loss = model.loss(y)\n",
    "        model.backward(y,0.1)\n",
    "        print(loss)\n",
    "\n",
    "def test():\n",
    "    y_preds = model(X)\n",
    "    output = np.where(y_preds >= 0.5, 1, 0)\n",
    "    accuracy = np.mean(output==y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baecac89-5230-4bc6-b8f4-536d4e61280e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775194641346328\n",
      "0.7450834314960167\n",
      "0.7175022612296622\n",
      "0.6921765042931759\n",
      "0.6688657665444544\n",
      "0.6471477112843749\n",
      "0.6270935829680429\n",
      "0.6085009288687514\n",
      "0.5910594675271195\n",
      "0.574613449280102\n",
      "0.5590575046617438\n",
      "0.544326604906801\n",
      "0.5303058649793632\n",
      "0.5168898200307266\n",
      "0.5041351766197524\n",
      "0.49197776775606483\n",
      "0.4802811306436924\n",
      "0.4690233637420203\n",
      "0.45815878827225714\n",
      "0.4476850273067417\n",
      "0.4375928097190858\n",
      "0.4278110193907079\n",
      "0.41833058985754706\n",
      "0.4091670311733761\n",
      "0.40032986791623854\n",
      "0.39178509416342067\n",
      "0.38354195098484467\n",
      "0.37553093573122565\n",
      "0.3677324410995222\n",
      "0.3601710612443673\n",
      "0.35283793397410806\n",
      "0.3457189662591251\n",
      "0.3388262738084407\n",
      "0.33217346081013743\n",
      "0.32571929547006606\n",
      "0.3194538224636058\n",
      "0.31336875388012503\n",
      "0.3074624278219699\n",
      "0.30172461294420805\n",
      "0.29616062032549\n",
      "0.2907585076571587\n",
      "0.28550312062952626\n",
      "0.2804027587969001\n",
      "0.275453508019757\n",
      "0.2706391567790853\n",
      "0.26597296925706776\n",
      "0.26145759586425005\n",
      "0.257092579071466\n",
      "0.2528434501137489\n",
      "0.24871962019933563\n",
      "0.2447211911946873\n",
      "0.24086445321338032\n",
      "0.2371452171045273\n",
      "0.23355467884203965\n",
      "0.23008042017243469\n",
      "0.2267115882527486\n",
      "0.22345072518932774\n",
      "0.22029461524148375\n",
      "0.21722835945499638\n",
      "0.21424892168948545\n",
      "0.2113534100875257\n",
      "0.20854035217407518\n",
      "0.20580568305025745\n",
      "0.2031395341970894\n",
      "0.20054849302833802\n",
      "0.1980287757491679\n",
      "0.19557377940352452\n",
      "0.19318725006295095\n",
      "0.19086765803824118\n",
      "0.18861271786586647\n",
      "0.18641950319756537\n",
      "0.1842891866960421\n",
      "0.1822138070902487\n",
      "0.1801991603926988\n",
      "0.17823840947113873\n",
      "0.17632735425260632\n",
      "0.174474381148108\n",
      "0.172673427100576\n",
      "0.170912637330915\n",
      "0.1691897406498434\n",
      "0.1675080291937734\n",
      "0.16586659349958693\n",
      "0.1642640959328721\n",
      "0.16269924341741984\n",
      "0.16116892766853155\n",
      "0.15966870502548797\n",
      "0.15820171649892614\n",
      "0.15674793697374298\n",
      "0.15532723907616217\n",
      "0.15393816931489912\n",
      "0.15257993478991105\n",
      "0.15125266577651628\n",
      "0.14995975685272867\n",
      "0.14869384850652967\n",
      "0.14744585133760824\n",
      "0.14622228962475628\n",
      "0.1450278051181464\n",
      "0.1438580336192336\n",
      "0.14271229379170847\n",
      "0.1415906555293289\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27e35d2b-8a88-4b25-92b9-4ee34ae7d4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f0086-b6aa-4eaa-b0b4-d779bacc0a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
